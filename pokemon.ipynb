{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ih5hGgux17cN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np # linear algebra\n",
        "from abc import ABC, abstractmethod\n",
        "from sklearn.base import TransformerMixin, clone\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import log_loss, make_scorer\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.feature_selection import f_classif,chi2, mutual_info_classif, SelectKBest, RFE, SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the size of your train and test data to model more easily\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "metadata": {
        "id": "VvU5hZuNIRdT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/pokemonnumber2.csv')"
      ],
      "metadata": {
        "id": "KyTHglnd2GDq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "mkKYUcTt24Mj",
        "outputId": "e17d791a-d2f0-4b24-a1b8-90c1621f3f8c",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     abilities  against_bug  against_dark  against_dragon  \\\n",
              "0  ['Overgrow', 'Chlorophyll']          1.0           1.0             1.0   \n",
              "1  ['Overgrow', 'Chlorophyll']          1.0           1.0             1.0   \n",
              "2  ['Overgrow', 'Chlorophyll']          1.0           1.0             1.0   \n",
              "3     ['Blaze', 'Solar Power']          0.5           1.0             1.0   \n",
              "4     ['Blaze', 'Solar Power']          0.5           1.0             1.0   \n",
              "\n",
              "   against_electric  against_fairy  against_fight  against_fire  \\\n",
              "0               0.5            0.5            0.5           2.0   \n",
              "1               0.5            0.5            0.5           2.0   \n",
              "2               0.5            0.5            0.5           2.0   \n",
              "3               1.0            0.5            1.0           0.5   \n",
              "4               1.0            0.5            1.0           0.5   \n",
              "\n",
              "   against_flying  against_ghost  ...  percentage_male  pokedex_number  \\\n",
              "0             2.0            1.0  ...             88.1               1   \n",
              "1             2.0            1.0  ...             88.1               2   \n",
              "2             2.0            1.0  ...             88.1               3   \n",
              "3             1.0            1.0  ...             88.1               4   \n",
              "4             1.0            1.0  ...             88.1               5   \n",
              "\n",
              "   sp_attack  sp_defense  speed  type1   type2  weight_kg  generation  \\\n",
              "0         65          65     45  grass  poison        6.9           1   \n",
              "1         80          80     60  grass  poison       13.0           1   \n",
              "2        122         120     80  grass  poison      100.0           1   \n",
              "3         60          50     65   fire     NaN        8.5           1   \n",
              "4         80          65     80   fire     NaN       19.0           1   \n",
              "\n",
              "   is_legendary  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             0  \n",
              "4             0  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb261c01-b7a6-461e-bf1f-bb2712a01ab1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abilities</th>\n",
              "      <th>against_bug</th>\n",
              "      <th>against_dark</th>\n",
              "      <th>against_dragon</th>\n",
              "      <th>against_electric</th>\n",
              "      <th>against_fairy</th>\n",
              "      <th>against_fight</th>\n",
              "      <th>against_fire</th>\n",
              "      <th>against_flying</th>\n",
              "      <th>against_ghost</th>\n",
              "      <th>...</th>\n",
              "      <th>percentage_male</th>\n",
              "      <th>pokedex_number</th>\n",
              "      <th>sp_attack</th>\n",
              "      <th>sp_defense</th>\n",
              "      <th>speed</th>\n",
              "      <th>type1</th>\n",
              "      <th>type2</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>generation</th>\n",
              "      <th>is_legendary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Overgrow', 'Chlorophyll']</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>88.1</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>45</td>\n",
              "      <td>grass</td>\n",
              "      <td>poison</td>\n",
              "      <td>6.9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Overgrow', 'Chlorophyll']</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>88.1</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "      <td>grass</td>\n",
              "      <td>poison</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Overgrow', 'Chlorophyll']</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>88.1</td>\n",
              "      <td>3</td>\n",
              "      <td>122</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>grass</td>\n",
              "      <td>poison</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Blaze', 'Solar Power']</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>88.1</td>\n",
              "      <td>4</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Blaze', 'Solar Power']</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>88.1</td>\n",
              "      <td>5</td>\n",
              "      <td>80</td>\n",
              "      <td>65</td>\n",
              "      <td>80</td>\n",
              "      <td>fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb261c01-b7a6-461e-bf1f-bb2712a01ab1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb261c01-b7a6-461e-bf1f-bb2712a01ab1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb261c01-b7a6-461e-bf1f-bb2712a01ab1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e73cef9-53bc-4a6b-a0cf-c63c8f704f0d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e73cef9-53bc-4a6b-a0cf-c63c8f704f0d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e73cef9-53bc-4a6b-a0cf-c63c8f704f0d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsL97xwo3AF-",
        "outputId": "8ee47dd7-e961-4782-c003-c9781645b1aa",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 801 entries, 0 to 800\n",
            "Data columns (total 41 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   abilities          801 non-null    object \n",
            " 1   against_bug        801 non-null    float64\n",
            " 2   against_dark       801 non-null    float64\n",
            " 3   against_dragon     801 non-null    float64\n",
            " 4   against_electric   801 non-null    float64\n",
            " 5   against_fairy      801 non-null    float64\n",
            " 6   against_fight      801 non-null    float64\n",
            " 7   against_fire       801 non-null    float64\n",
            " 8   against_flying     801 non-null    float64\n",
            " 9   against_ghost      801 non-null    float64\n",
            " 10  against_grass      801 non-null    float64\n",
            " 11  against_ground     801 non-null    float64\n",
            " 12  against_ice        801 non-null    float64\n",
            " 13  against_normal     801 non-null    float64\n",
            " 14  against_poison     801 non-null    float64\n",
            " 15  against_psychic    801 non-null    float64\n",
            " 16  against_rock       801 non-null    float64\n",
            " 17  against_steel      801 non-null    float64\n",
            " 18  against_water      801 non-null    float64\n",
            " 19  attack             801 non-null    int64  \n",
            " 20  base_egg_steps     801 non-null    int64  \n",
            " 21  base_happiness     801 non-null    int64  \n",
            " 22  base_total         801 non-null    int64  \n",
            " 23  capture_rate       801 non-null    object \n",
            " 24  classfication      801 non-null    object \n",
            " 25  defense            801 non-null    int64  \n",
            " 26  experience_growth  801 non-null    int64  \n",
            " 27  height_m           781 non-null    float64\n",
            " 28  hp                 801 non-null    int64  \n",
            " 29  japanese_name      801 non-null    object \n",
            " 30  name               801 non-null    object \n",
            " 31  percentage_male    703 non-null    float64\n",
            " 32  pokedex_number     801 non-null    int64  \n",
            " 33  sp_attack          801 non-null    int64  \n",
            " 34  sp_defense         801 non-null    int64  \n",
            " 35  speed              801 non-null    int64  \n",
            " 36  type1              801 non-null    object \n",
            " 37  type2              417 non-null    object \n",
            " 38  weight_kg          781 non-null    float64\n",
            " 39  generation         801 non-null    int64  \n",
            " 40  is_legendary       801 non-null    int64  \n",
            "dtypes: float64(21), int64(13), object(7)\n",
            "memory usage: 256.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "QS01YOv_3jLE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "collapsed": true,
        "outputId": "b7e76077-b9a6-40b0-adad-cc4f8a9c9fc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       against_bug  against_dark  against_dragon  against_electric  \\\n",
              "count   801.000000    801.000000      801.000000        801.000000   \n",
              "mean      0.996255      1.057116        0.968789          1.073970   \n",
              "std       0.597248      0.438142        0.353058          0.654962   \n",
              "min       0.250000      0.250000        0.000000          0.000000   \n",
              "25%       0.500000      1.000000        1.000000          0.500000   \n",
              "50%       1.000000      1.000000        1.000000          1.000000   \n",
              "75%       1.000000      1.000000        1.000000          1.000000   \n",
              "max       4.000000      4.000000        2.000000          4.000000   \n",
              "\n",
              "       against_fairy  against_fight  against_fire  against_flying  \\\n",
              "count     801.000000     801.000000    801.000000      801.000000   \n",
              "mean        1.068976       1.065543      1.135456        1.192884   \n",
              "std         0.522167       0.717251      0.691853        0.604488   \n",
              "min         0.250000       0.000000      0.250000        0.250000   \n",
              "25%         1.000000       0.500000      0.500000        1.000000   \n",
              "50%         1.000000       1.000000      1.000000        1.000000   \n",
              "75%         1.000000       1.000000      2.000000        1.000000   \n",
              "max         4.000000       4.000000      4.000000        4.000000   \n",
              "\n",
              "       against_ghost  against_grass  ...    height_m          hp  \\\n",
              "count     801.000000     801.000000  ...  781.000000  801.000000   \n",
              "mean        0.985019       1.034020  ...    1.163892   68.958801   \n",
              "std         0.558256       0.788896  ...    1.080326   26.576015   \n",
              "min         0.000000       0.250000  ...    0.100000    1.000000   \n",
              "25%         1.000000       0.500000  ...    0.600000   50.000000   \n",
              "50%         1.000000       1.000000  ...    1.000000   65.000000   \n",
              "75%         1.000000       1.000000  ...    1.500000   80.000000   \n",
              "max         4.000000       4.000000  ...   14.500000  255.000000   \n",
              "\n",
              "       percentage_male  pokedex_number   sp_attack  sp_defense       speed  \\\n",
              "count       703.000000      801.000000  801.000000  801.000000  801.000000   \n",
              "mean         55.155761      401.000000   71.305868   70.911361   66.334582   \n",
              "std          20.261623      231.373075   32.353826   27.942501   28.907662   \n",
              "min           0.000000        1.000000   10.000000   20.000000    5.000000   \n",
              "25%          50.000000      201.000000   45.000000   50.000000   45.000000   \n",
              "50%          50.000000      401.000000   65.000000   66.000000   65.000000   \n",
              "75%          50.000000      601.000000   91.000000   90.000000   85.000000   \n",
              "max         100.000000      801.000000  194.000000  230.000000  180.000000   \n",
              "\n",
              "        weight_kg  generation  is_legendary  \n",
              "count  781.000000  801.000000    801.000000  \n",
              "mean    61.378105    3.690387      0.087391  \n",
              "std    109.354766    1.930420      0.282583  \n",
              "min      0.100000    1.000000      0.000000  \n",
              "25%      9.000000    2.000000      0.000000  \n",
              "50%     27.300000    4.000000      0.000000  \n",
              "75%     64.800000    5.000000      0.000000  \n",
              "max    999.900000    7.000000      1.000000  \n",
              "\n",
              "[8 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58eb9765-8ae2-4d24-b1cc-1b63f0319cd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>against_bug</th>\n",
              "      <th>against_dark</th>\n",
              "      <th>against_dragon</th>\n",
              "      <th>against_electric</th>\n",
              "      <th>against_fairy</th>\n",
              "      <th>against_fight</th>\n",
              "      <th>against_fire</th>\n",
              "      <th>against_flying</th>\n",
              "      <th>against_ghost</th>\n",
              "      <th>against_grass</th>\n",
              "      <th>...</th>\n",
              "      <th>height_m</th>\n",
              "      <th>hp</th>\n",
              "      <th>percentage_male</th>\n",
              "      <th>pokedex_number</th>\n",
              "      <th>sp_attack</th>\n",
              "      <th>sp_defense</th>\n",
              "      <th>speed</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>generation</th>\n",
              "      <th>is_legendary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>781.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>703.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>781.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>801.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.996255</td>\n",
              "      <td>1.057116</td>\n",
              "      <td>0.968789</td>\n",
              "      <td>1.073970</td>\n",
              "      <td>1.068976</td>\n",
              "      <td>1.065543</td>\n",
              "      <td>1.135456</td>\n",
              "      <td>1.192884</td>\n",
              "      <td>0.985019</td>\n",
              "      <td>1.034020</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163892</td>\n",
              "      <td>68.958801</td>\n",
              "      <td>55.155761</td>\n",
              "      <td>401.000000</td>\n",
              "      <td>71.305868</td>\n",
              "      <td>70.911361</td>\n",
              "      <td>66.334582</td>\n",
              "      <td>61.378105</td>\n",
              "      <td>3.690387</td>\n",
              "      <td>0.087391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.597248</td>\n",
              "      <td>0.438142</td>\n",
              "      <td>0.353058</td>\n",
              "      <td>0.654962</td>\n",
              "      <td>0.522167</td>\n",
              "      <td>0.717251</td>\n",
              "      <td>0.691853</td>\n",
              "      <td>0.604488</td>\n",
              "      <td>0.558256</td>\n",
              "      <td>0.788896</td>\n",
              "      <td>...</td>\n",
              "      <td>1.080326</td>\n",
              "      <td>26.576015</td>\n",
              "      <td>20.261623</td>\n",
              "      <td>231.373075</td>\n",
              "      <td>32.353826</td>\n",
              "      <td>27.942501</td>\n",
              "      <td>28.907662</td>\n",
              "      <td>109.354766</td>\n",
              "      <td>1.930420</td>\n",
              "      <td>0.282583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>201.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>401.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>601.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>64.800000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>230.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>999.900000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58eb9765-8ae2-4d24-b1cc-1b63f0319cd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58eb9765-8ae2-4d24-b1cc-1b63f0319cd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58eb9765-8ae2-4d24-b1cc-1b63f0319cd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb8c378a-4160-4562-a72e-0f8c7e74791e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb8c378a-4160-4562-a72e-0f8c7e74791e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb8c378a-4160-4562-a72e-0f8c7e74791e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "xE6IUroK3vGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7139e78c-06af-41de-8641-7c1b92a27a2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "abilities              0\n",
              "against_bug            0\n",
              "against_dark           0\n",
              "against_dragon         0\n",
              "against_electric       0\n",
              "against_fairy          0\n",
              "against_fight          0\n",
              "against_fire           0\n",
              "against_flying         0\n",
              "against_ghost          0\n",
              "against_grass          0\n",
              "against_ground         0\n",
              "against_ice            0\n",
              "against_normal         0\n",
              "against_poison         0\n",
              "against_psychic        0\n",
              "against_rock           0\n",
              "against_steel          0\n",
              "against_water          0\n",
              "attack                 0\n",
              "base_egg_steps         0\n",
              "base_happiness         0\n",
              "base_total             0\n",
              "capture_rate           0\n",
              "classfication          0\n",
              "defense                0\n",
              "experience_growth      0\n",
              "height_m              20\n",
              "hp                     0\n",
              "japanese_name          0\n",
              "name                   0\n",
              "percentage_male       98\n",
              "pokedex_number         0\n",
              "sp_attack              0\n",
              "sp_defense             0\n",
              "speed                  0\n",
              "type1                  0\n",
              "type2                384\n",
              "weight_kg             20\n",
              "generation             0\n",
              "is_legendary           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search the column names with missing values\n",
        "cols_missing_val = df.columns[df.isnull().any()].tolist()\n",
        "\n",
        "for col in cols_missing_val:\n",
        "    print(\"%s : %d\" % (col, df[col].isnull().sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmSGjwNbFC4q",
        "outputId": "3bf4e7dd-6604-40d8-e6cd-a514cc7c1eb7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "height_m : 20\n",
            "percentage_male : 98\n",
            "type2 : 384\n",
            "weight_kg : 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **here, we fill the missing**"
      ],
      "metadata": {
        "id": "zacvmHF7G57y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hence genderless pokemons can be assigned '-1'\n",
        "df['percentage_male'].fillna(int(-1), inplace=True)"
      ],
      "metadata": {
        "id": "jrfoWlmbGEoW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unique values\n",
        "df['type2'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKfW5hsKGErU",
        "outputId": "df751898-b427-4528-ba4d-54ccca44456c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['poison', nan, 'flying', 'dark', 'electric', 'ice', 'ground',\n",
              "       'fairy', 'grass', 'fighting', 'psychic', 'steel', 'fire', 'rock',\n",
              "       'water', 'dragon', 'ghost', 'bug', 'normal'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace nan with new type2\n",
        "df['type2'].fillna('hormann', inplace=True)"
      ],
      "metadata": {
        "id": "YVFHKcNGGEuF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace the missing values with 0.\n",
        "df['height_m'].fillna(int(0), inplace=True)\n",
        "df['weight_kg'].fillna(int(0), inplace=True)"
      ],
      "metadata": {
        "id": "j4xtVjQGGEwn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Memory Consumption\n",
        "mem = df.memory_usage(index=True).sum()\n",
        "print(\"Memory consumed by training set  :   {} MB\" .format(mem/ 1024**2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dupTmnwQHF9i",
        "outputId": "3fa69a66-c1ad-4479-ec32-64876496bff5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory consumed by training set  :   0.25067901611328125 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-DMQY8hGE0K",
        "outputId": "ebd6668d-ed23-45bb-a44e-ce7dff1fc141"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = reduce_mem_usage(df, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGmYeZqFHO5l",
        "outputId": "aa2a15db-7147-42b3-a2f8-d30e204a3230"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mem. usage decreased to  0.13 Mb (49.4% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classfication\n",
        "df['classfication'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLc2fCprHehV",
        "outputId": "f5244deb-fc3b-42e2-c56a-90ec27de4989"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "588"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprosseing for make it int"
      ],
      "metadata": {
        "id": "M1AYBEyQKOw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "Ua6SQik_Hej7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "49d31ebb-aa04-4508-d3f7-1c27343ef351"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "abilities             object\n",
              "against_bug          float32\n",
              "against_dark         float32\n",
              "against_dragon       float32\n",
              "against_electric     float32\n",
              "against_fairy        float32\n",
              "against_fight        float32\n",
              "against_fire         float32\n",
              "against_flying       float32\n",
              "against_ghost        float32\n",
              "against_grass        float32\n",
              "against_ground       float32\n",
              "against_ice          float32\n",
              "against_normal       float32\n",
              "against_poison       float32\n",
              "against_psychic      float32\n",
              "against_rock         float32\n",
              "against_steel        float32\n",
              "against_water        float32\n",
              "attack                 int16\n",
              "base_egg_steps         int16\n",
              "base_happiness         int16\n",
              "base_total             int16\n",
              "capture_rate          object\n",
              "classfication         object\n",
              "defense                int16\n",
              "experience_growth      int32\n",
              "height_m             float32\n",
              "hp                     int16\n",
              "japanese_name         object\n",
              "name                  object\n",
              "percentage_male      float32\n",
              "pokedex_number         int16\n",
              "sp_attack              int16\n",
              "sp_defense             int16\n",
              "speed                  int16\n",
              "type1                 object\n",
              "type2                 object\n",
              "weight_kg            float32\n",
              "generation              int8\n",
              "is_legendary            int8\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label,content in df.items():\n",
        "    if pd.api.types.is_float_dtype(content):\n",
        "        df[label] = df[label].astype('int')"
      ],
      "metadata": {
        "id": "wdttT2jSHemg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label,content in df.items():\n",
        "    if not pd.api.types.is_numeric_dtype(content):\n",
        "        df[label] = df[label].astype('category')\n"
      ],
      "metadata": {
        "id": "XUyu0GoyHO9A",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label,content in df.items():\n",
        "    if pd.api.types.is_categorical_dtype(content):\n",
        "        df[label] = pd.Categorical(content).codes + 1"
      ],
      "metadata": {
        "id": "g7iIgrUgJxDC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIzZAd5cJ2Ds",
        "outputId": "39d50b7d-9033-4e3e-f0ac-0fb2dcea9472",
        "collapsed": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "abilities            int16\n",
              "against_bug          int64\n",
              "against_dark         int64\n",
              "against_dragon       int64\n",
              "against_electric     int64\n",
              "against_fairy        int64\n",
              "against_fight        int64\n",
              "against_fire         int64\n",
              "against_flying       int64\n",
              "against_ghost        int64\n",
              "against_grass        int64\n",
              "against_ground       int64\n",
              "against_ice          int64\n",
              "against_normal       int64\n",
              "against_poison       int64\n",
              "against_psychic      int64\n",
              "against_rock         int64\n",
              "against_steel        int64\n",
              "against_water        int64\n",
              "attack               int16\n",
              "base_egg_steps       int16\n",
              "base_happiness       int16\n",
              "base_total           int16\n",
              "capture_rate          int8\n",
              "classfication        int16\n",
              "defense              int16\n",
              "experience_growth    int32\n",
              "height_m             int64\n",
              "hp                   int16\n",
              "japanese_name        int16\n",
              "name                 int16\n",
              "percentage_male      int64\n",
              "pokedex_number       int16\n",
              "sp_attack            int16\n",
              "sp_defense           int16\n",
              "speed                int16\n",
              "type1                 int8\n",
              "type2                 int8\n",
              "weight_kg            int64\n",
              "generation            int8\n",
              "is_legendary          int8\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just for show\n",
        "plt.pie(x=df['is_legendary'].value_counts(),autopct='%0.2f',labels=['non-legendary','legendary'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VQ8J-dkp366T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "68e98d8f-2e25-494c-f58b-947ebd3944bf",
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Model Training SVC ***\n"
      ],
      "metadata": {
        "id": "aWhaT-VB7nLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train test split"
      ],
      "metadata": {
        "id": "3AlmCoL07UC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_old= df.drop(labels= 'is_legendary', axis= 1)\n",
        "y_old = df['is_legendary']"
      ],
      "metadata": {
        "id": "0QOWqnPLjHS4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_a = SVC()\n",
        "X_train_old, X_test_old, y_train_old, y_test_old = train_test_split(X_old, y_old, test_size=0.3)\n",
        "model_a.fit(X_train_old, y_train_old)\n",
        "model_a.score(X_test_old, y_test_old)"
      ],
      "metadata": {
        "id": "fjkUWFzVJ2Iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d11a468-a76d-4aa2-c67a-dcc5099eb164",
        "collapsed": true
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9004149377593361"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions\n",
        "y_pred_old = model_a.predict(X_test_old)\n",
        "\n",
        "# Calculate metrics\n",
        "report = classification_report(y_test_old, y_pred_old)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUjG1v_csS3u",
        "outputId": "f536d7a8-b1ee-42b4-f2c0-c1593a2d6ebd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95       217\n",
            "           1       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.90       241\n",
            "   macro avg       0.45      0.50      0.47       241\n",
            "weighted avg       0.81      0.90      0.85       241\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature selection**"
      ],
      "metadata": {
        "id": "y2GeYUs4kH9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['is_legendary']"
      ],
      "metadata": {
        "id": "STytTaeKJ2GR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#noha\n",
        "def calculate_accuracy(x):\n",
        "    X=df[x]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.30)\n",
        "    lgt_R = LogisticRegression(solver='lbfgs')\n",
        "    lgt_R.fit(X_train, y_train)\n",
        "    accuracy=lgt_R.score(X_test,y_test)\n",
        "    print('Accuracy:',accuracy)\n",
        "\n",
        "    y_pred = lgt_R.predict(X_test)\n",
        "    print('Classification Report:')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return accuracy, classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "UyCbnGyw_Exy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(labels= 'is_legendary', axis= 1).columns.values.tolist()#columnsName->X"
      ],
      "metadata": {
        "id": "x1X7iKsLBVci"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "columnsName1=[0,1]\n",
        "chromosomes=[]\n",
        "for i in range(10):\n",
        "    chro1=[]\n",
        "    for i in range(40):\n",
        "        item = random.choice(tuple(columnsName1))\n",
        "        chro1.append(item)\n",
        "    chromosomes.append(chro1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2lYr1ldSANW9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data(chromosomes1):\n",
        "    chromosomes2=[]\n",
        "    for i in range(len(chromosomes1)):\n",
        "        if chromosomes1[i]==1:\n",
        "                chromosomes2.append(X[i])\n",
        "    return chromosomes2"
      ],
      "metadata": {
        "id": "ZEAjpFpUBVfI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the final accuracy for"
      ],
      "metadata": {
        "id": "eWKH1WCqHmSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pb=[]\n",
        "def checkpersonalnest():\n",
        "    for i in range(len(chromosomes)):\n",
        "         pb.append(calculate_accuracy(data(chromosomes[i])))\n",
        "checkpersonalnest()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ipD28udmBVij",
        "outputId": "cdce00a9-8a3a-44a3-8137-58a21193d451"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.921161825726141\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96       219\n",
            "           1       0.67      0.27      0.39        22\n",
            "\n",
            "    accuracy                           0.92       241\n",
            "   macro avg       0.80      0.63      0.67       241\n",
            "weighted avg       0.91      0.92      0.91       241\n",
            "\n",
            "Accuracy: 0.946058091286307\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       217\n",
            "           1       0.82      0.58      0.68        24\n",
            "\n",
            "    accuracy                           0.95       241\n",
            "   macro avg       0.89      0.78      0.83       241\n",
            "weighted avg       0.94      0.95      0.94       241\n",
            "\n",
            "Accuracy: 0.9336099585062241\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97       230\n",
            "           1       0.14      0.09      0.11        11\n",
            "\n",
            "    accuracy                           0.93       241\n",
            "   macro avg       0.55      0.53      0.54       241\n",
            "weighted avg       0.92      0.93      0.93       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       217\n",
            "           1       0.96      0.92      0.94        24\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.96      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       225\n",
            "           1       0.94      0.94      0.94        16\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.97      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       223\n",
            "           1       0.94      0.83      0.88        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.91      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9336099585062241\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       220\n",
            "           1       0.73      0.38      0.50        21\n",
            "\n",
            "    accuracy                           0.93       241\n",
            "   macro avg       0.84      0.68      0.73       241\n",
            "weighted avg       0.92      0.93      0.92       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       218\n",
            "           1       1.00      0.87      0.93        23\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.99      0.93      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       231\n",
            "           1       0.80      0.80      0.80        10\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.90      0.90      0.90       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9004149377593361\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95       218\n",
            "           1       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.90       241\n",
            "   macro avg       0.45      0.50      0.47       241\n",
            "weighted avg       0.82      0.90      0.86       241\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PSO**"
      ],
      "metadata": {
        "id": "LSShJjs8G-gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkvelocity(globalbest):\n",
        "    velocity=[]\n",
        "    for j in range(len(chromosomes)):\n",
        "        velocity.append(list(0+1*(np.random.random(1)[0])*(np.array(chromosomes[j])-np.array(chromosomes[j]))+1*(np.random.random(1)[0])*(np.array(globalbest)-np.array(chromosomes[j]))))\n",
        "    #print(velocity)\n",
        "    return velocity\n"
      ],
      "metadata": {
        "id": "HpCovbipBVps"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addingchromosomes(velocity):\n",
        "    chromosomes2=[]\n",
        "    for i in range(len(velocity)):\n",
        "        nextchromo=[]\n",
        "        for j in range(len(velocity[i])):\n",
        "            nextchromo.append(chromosomes[i][j]+velocity[i][j])\n",
        "        chromosomes2.append(nextchromo)\n",
        "    return chromosomes2"
      ],
      "metadata": {
        "id": "GWcV5sQME6Z_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(chromosomes2):\n",
        "    for l in range(len(chromosomes2)):\n",
        "        for m in range(len(chromosomes2[l])):\n",
        "            if chromosomes2[l][m]>0.5:\n",
        "                chromosomes2[l][m]=1\n",
        "            else:\n",
        "                chromosomes2[l][m]=0\n",
        "    return chromosomes2"
      ],
      "metadata": {
        "id": "lRF28TeH_jZo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpd(chromosomes2):\n",
        "    personal=[]\n",
        "    for i in range(len(chromosomes2)):\n",
        "        personal.append(calculate_accuracy(data(chromosomes2[i])))\n",
        "    for j in range(len(personal)):\n",
        "        if(personal[j]>pb[j]):\n",
        "            chromosomes[j]=chromosomes2[j]\n",
        "            pb[j]=personal[j]\n",
        "    return personal"
      ],
      "metadata": {
        "id": "oRlcTXUuFP8A"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(pb)\n",
        "ind = pb.index(max(pb))\n",
        "globalbest=chromosomes[ind]\n",
        "for i in range(30):\n",
        "    chromosomes2=[]\n",
        "    personal=[]\n",
        "    velocity=checkvelocity(globalbest)\n",
        "    chromosomes2=addingchromosomes(velocity)\n",
        "    chromosomes2=normalize(chromosomes2)\n",
        "    personal=checkpd(chromosomes2)\n",
        "    globalbest=[]\n",
        "    max(pb)\n",
        "    ind = pb.index(max(pb))\n",
        "    globalbest=chromosomes[ind]\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GfACTYYJFP-1",
        "outputId": "90ebd434-1273-4370-a083-bf9567bf9f32"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       223\n",
            "           1       0.88      0.83      0.86        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.91      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.950207468879668\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       218\n",
            "           1       1.00      0.48      0.65        23\n",
            "\n",
            "    accuracy                           0.95       241\n",
            "   macro avg       0.97      0.74      0.81       241\n",
            "weighted avg       0.95      0.95      0.94       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.88      0.88      0.88        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.94      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       224\n",
            "           1       1.00      0.76      0.87        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.88      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       225\n",
            "           1       0.79      0.69      0.73        16\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.88      0.84      0.86       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       224\n",
            "           1       1.00      0.88      0.94        17\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       1.00      0.94      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.9087136929460581\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       215\n",
            "           1       0.59      0.50      0.54        26\n",
            "\n",
            "    accuracy                           0.91       241\n",
            "   macro avg       0.77      0.73      0.75       241\n",
            "weighted avg       0.90      0.91      0.91       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       220\n",
            "           1       1.00      0.90      0.95        21\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       1.00      0.95      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       219\n",
            "           1       0.83      0.86      0.84        22\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.92      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       217\n",
            "           1       0.85      0.92      0.88        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.95      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       224\n",
            "           1       0.94      0.94      0.94        17\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.97      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.9336099585062241\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       224\n",
            "           1       0.56      0.29      0.38        17\n",
            "\n",
            "    accuracy                           0.93       241\n",
            "   macro avg       0.75      0.64      0.67       241\n",
            "weighted avg       0.92      0.93      0.92       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.90      0.90      0.90        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       220\n",
            "           1       0.83      0.90      0.86        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.94      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       219\n",
            "           1       1.00      0.95      0.98        22\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      0.98      0.99       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       216\n",
            "           1       1.00      0.84      0.91        25\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.92      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.946058091286307\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       221\n",
            "           1       0.68      0.65      0.67        20\n",
            "\n",
            "    accuracy                           0.95       241\n",
            "   macro avg       0.83      0.81      0.82       241\n",
            "weighted avg       0.94      0.95      0.95       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       222\n",
            "           1       0.94      0.89      0.92        19\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.95      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       218\n",
            "           1       0.86      0.78      0.82        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.88      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       220\n",
            "           1       0.95      0.86      0.90        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.93      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       219\n",
            "           1       0.95      0.91      0.93        22\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.95      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.9377593360995851\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       214\n",
            "           1       0.93      0.48      0.63        27\n",
            "\n",
            "    accuracy                           0.94       241\n",
            "   macro avg       0.93      0.74      0.80       241\n",
            "weighted avg       0.94      0.94      0.93       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       219\n",
            "           1       0.91      0.91      0.91        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       217\n",
            "           1       1.00      0.79      0.88        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.90      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       223\n",
            "           1       0.84      0.89      0.86        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.94      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9626556016597511\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       220\n",
            "           1       0.83      0.71      0.77        21\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.90      0.85      0.87       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       220\n",
            "           1       0.87      0.95      0.91        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.97      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       221\n",
            "           1       1.00      0.95      0.97        20\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      0.97      0.99       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.90      0.86      0.88        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       221\n",
            "           1       0.79      0.95      0.86        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.89      0.96      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       221\n",
            "           1       1.00      0.75      0.86        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.88      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       223\n",
            "           1       0.94      0.89      0.91        18\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.94      0.95       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       225\n",
            "           1       0.87      0.81      0.84        16\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.90      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       221\n",
            "           1       0.86      0.95      0.90        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.97      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       213\n",
            "           1       0.96      0.89      0.93        28\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.94      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       220\n",
            "           1       0.83      0.90      0.86        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.94      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       221\n",
            "           1       0.79      0.95      0.86        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.89      0.96      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       216\n",
            "           1       0.88      0.84      0.86        25\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.93      0.91      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       221\n",
            "           1       0.89      0.80      0.84        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.90      0.91       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       222\n",
            "           1       0.84      0.84      0.84        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.91      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       219\n",
            "           1       0.94      0.77      0.85        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.88      0.92       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       219\n",
            "           1       0.91      0.91      0.91        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       224\n",
            "           1       0.87      0.76      0.81        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.88      0.90       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.86      0.90      0.88        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.95      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       216\n",
            "           1       1.00      0.84      0.91        25\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.92      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       218\n",
            "           1       0.87      0.87      0.87        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.93      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       222\n",
            "           1       0.85      0.89      0.87        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.94      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       210\n",
            "           1       0.97      0.90      0.93        31\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.98      0.95      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       218\n",
            "           1       0.90      0.83      0.86        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.91      0.92       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.89      0.85      0.87        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.88      0.82      0.85        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.91      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       225\n",
            "           1       1.00      0.81      0.90        16\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.99      0.91      0.94       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98       219\n",
            "           1       0.75      0.95      0.84        22\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.87      0.96      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       222\n",
            "           1       1.00      0.89      0.94        19\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       1.00      0.95      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       213\n",
            "           1       0.86      0.89      0.88        28\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.94      0.93       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       225\n",
            "           1       0.80      0.75      0.77        16\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.89      0.87      0.88       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.9585062240663901\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       214\n",
            "           1       0.81      0.81      0.81        27\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.90      0.90      0.90       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.88      0.88      0.88        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.94      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       222\n",
            "           1       0.88      0.79      0.83        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.89      0.91       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       221\n",
            "           1       0.89      0.80      0.84        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.90      0.91       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       225\n",
            "           1       0.83      0.94      0.88        16\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.96      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       214\n",
            "           1       0.92      0.81      0.86        27\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.95      0.90      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       220\n",
            "           1       1.00      0.71      0.83        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.86      0.91       241\n",
            "weighted avg       0.98      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       220\n",
            "           1       1.00      0.90      0.95        21\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       1.00      0.95      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       216\n",
            "           1       0.91      0.84      0.87        25\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.92      0.93       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       219\n",
            "           1       0.86      0.82      0.84        22\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.90      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       219\n",
            "           1       0.85      0.77      0.81        22\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.88      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       228\n",
            "           1       0.69      0.85      0.76        13\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.84      0.91      0.87       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       216\n",
            "           1       0.87      0.80      0.83        25\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.89      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       227\n",
            "           1       0.82      1.00      0.90        14\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.91      0.99      0.95       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       216\n",
            "           1       1.00      0.96      0.98        25\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      0.98      0.99       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.90      0.86      0.88        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       226\n",
            "           1       0.92      0.80      0.86        15\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.90      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       221\n",
            "           1       0.90      0.95      0.93        20\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.95      0.97      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.85      0.85      0.85        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.92      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.85      0.85      0.85        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.92      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       224\n",
            "           1       0.74      0.82      0.78        17\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.86      0.90      0.88       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       220\n",
            "           1       0.82      0.86      0.84        21\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.90      0.92      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       215\n",
            "           1       0.91      0.81      0.86        26\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.95      0.90      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       220\n",
            "           1       1.00      0.86      0.92        21\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.99      0.93      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       215\n",
            "           1       0.85      0.85      0.85        26\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.91      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.85      0.85      0.85        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.92      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9585062240663901\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       220\n",
            "           1       0.79      0.71      0.75        21\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.88      0.85      0.86       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       222\n",
            "           1       0.81      0.89      0.85        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.90      0.94      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       220\n",
            "           1       1.00      0.81      0.89        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.90      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.90      0.90      0.90        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       217\n",
            "           1       1.00      0.88      0.93        24\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.99      0.94      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       229\n",
            "           1       0.83      0.83      0.83        12\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.91      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       223\n",
            "           1       1.00      1.00      1.00        18\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      1.00      1.00       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.82      0.82      0.82        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.91      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9626556016597511\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       217\n",
            "           1       0.86      0.75      0.80        24\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.91      0.87      0.89       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       212\n",
            "           1       1.00      0.83      0.91        29\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.91      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       224\n",
            "           1       0.85      0.65      0.73        17\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.82      0.86       241\n",
            "weighted avg       0.96      0.97      0.96       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       222\n",
            "           1       0.94      0.84      0.89        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       222\n",
            "           1       0.94      0.84      0.89        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       217\n",
            "           1       0.84      0.88      0.86        24\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.93      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       219\n",
            "           1       0.86      0.86      0.86        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.92      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       219\n",
            "           1       0.95      0.95      0.95        22\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.97      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       223\n",
            "           1       1.00      0.83      0.91        18\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.99      0.92      0.95       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.90      0.86      0.88        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       223\n",
            "           1       0.89      0.94      0.92        18\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.95      0.97      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       218\n",
            "           1       0.95      0.87      0.91        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.93      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       212\n",
            "           1       1.00      0.86      0.93        29\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.93      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       218\n",
            "           1       0.95      0.87      0.91        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.93      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       222\n",
            "           1       0.88      0.79      0.83        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.89      0.91       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       218\n",
            "           1       0.95      0.91      0.93        23\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.95      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       222\n",
            "           1       0.94      0.89      0.92        19\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.95      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       217\n",
            "           1       0.95      0.88      0.91        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.94      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       222\n",
            "           1       0.89      0.84      0.86        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       218\n",
            "           1       0.86      0.78      0.82        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.88      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       214\n",
            "           1       1.00      0.81      0.90        27\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.91      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       223\n",
            "           1       0.82      0.78      0.80        18\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.90      0.88      0.89       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       218\n",
            "           1       0.86      0.83      0.84        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.91      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       221\n",
            "           1       1.00      0.80      0.89        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.90      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       215\n",
            "           1       0.92      0.88      0.90        26\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.94      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       216\n",
            "           1       0.96      0.88      0.92        25\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.94      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       218\n",
            "           1       0.90      0.78      0.84        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.94      0.89      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       222\n",
            "           1       0.80      0.84      0.82        19\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.89      0.91      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       221\n",
            "           1       0.94      0.85      0.89        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       225\n",
            "           1       0.75      0.94      0.83        16\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.87      0.96      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       224\n",
            "           1       0.94      0.88      0.91        17\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.96      0.94      0.95       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       226\n",
            "           1       0.87      0.87      0.87        15\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.93      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       222\n",
            "           1       0.76      0.84      0.80        19\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.87      0.91      0.89       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       225\n",
            "           1       1.00      0.88      0.93        16\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       1.00      0.94      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       220\n",
            "           1       0.95      0.86      0.90        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.93      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       219\n",
            "           1       0.95      0.82      0.88        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.91      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       225\n",
            "           1       0.89      1.00      0.94        16\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.94      1.00      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       219\n",
            "           1       0.91      0.91      0.91        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       214\n",
            "           1       1.00      0.93      0.96        27\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       1.00      0.96      0.98       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       222\n",
            "           1       0.89      0.84      0.86        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       218\n",
            "           1       0.87      0.87      0.87        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.93      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       218\n",
            "           1       1.00      0.83      0.90        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.91      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       218\n",
            "           1       0.83      0.87      0.85        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.93      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       226\n",
            "           1       0.76      0.87      0.81        15\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.88      0.92      0.90       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       217\n",
            "           1       0.88      0.92      0.90        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.95      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       219\n",
            "           1       0.92      1.00      0.96        22\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.96      1.00      0.98       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       223\n",
            "           1       0.94      0.89      0.91        18\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.94      0.95       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       214\n",
            "           1       0.92      0.89      0.91        27\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.94      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       227\n",
            "           1       0.87      0.93      0.90        14\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.93      0.96      0.94       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       223\n",
            "           1       0.76      0.89      0.82        18\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.88      0.93      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       223\n",
            "           1       1.00      0.72      0.84        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.86      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       222\n",
            "           1       0.78      0.95      0.86        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.89      0.96      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9585062240663901\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       219\n",
            "           1       0.83      0.68      0.75        22\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.90      0.83      0.86       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       216\n",
            "           1       0.91      0.80      0.85        25\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.94      0.90      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       218\n",
            "           1       0.86      0.78      0.82        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.88      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.9626556016597511\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       213\n",
            "           1       0.95      0.71      0.82        28\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.96      0.85      0.90       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       223\n",
            "           1       0.77      0.94      0.85        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.88      0.96      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       222\n",
            "           1       0.94      0.89      0.92        19\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.95      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       214\n",
            "           1       0.96      0.81      0.88        27\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.91      0.93       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       215\n",
            "           1       0.96      0.85      0.90        26\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       217\n",
            "           1       0.95      0.88      0.91        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.94      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       219\n",
            "           1       0.95      0.86      0.90        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.93      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       217\n",
            "           1       0.95      0.79      0.86        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.89      0.92       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       215\n",
            "           1       0.96      0.92      0.94        26\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.98      0.96      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       217\n",
            "           1       0.88      0.96      0.92        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.97      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       220\n",
            "           1       1.00      0.81      0.89        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.90      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       218\n",
            "           1       0.94      0.70      0.80        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.95      0.85      0.89       241\n",
            "weighted avg       0.97      0.97      0.96       241\n",
            "\n",
            "Accuracy: 0.9543568464730291\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98       222\n",
            "           1       0.68      0.79      0.73        19\n",
            "\n",
            "    accuracy                           0.95       241\n",
            "   macro avg       0.83      0.88      0.85       241\n",
            "weighted avg       0.96      0.95      0.96       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       213\n",
            "           1       0.88      0.82      0.85        28\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.93      0.90      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       223\n",
            "           1       0.81      0.94      0.87        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.90      0.96      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       219\n",
            "           1       1.00      0.95      0.98        22\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      0.98      0.99       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       222\n",
            "           1       0.89      0.84      0.86        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.86      0.90      0.88        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.95      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.82      0.82      0.82        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.91      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       223\n",
            "           1       1.00      0.78      0.88        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.89      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       226\n",
            "           1       0.92      0.73      0.81        15\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.86      0.90       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9626556016597511\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       216\n",
            "           1       0.86      0.76      0.81        25\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.92      0.87      0.89       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       213\n",
            "           1       0.96      0.89      0.93        28\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.94      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.90      0.86      0.88        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       218\n",
            "           1       0.91      0.91      0.91        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       220\n",
            "           1       0.82      0.86      0.84        21\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.90      0.92      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       229\n",
            "           1       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.96      0.96      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       224\n",
            "           1       0.87      0.76      0.81        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.88      0.90       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       219\n",
            "           1       1.00      0.68      0.81        22\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.98      0.84      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       221\n",
            "           1       1.00      0.75      0.86        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.88      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       219\n",
            "           1       0.95      0.86      0.90        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.93      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       216\n",
            "           1       0.92      0.92      0.92        25\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.96      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       218\n",
            "           1       0.91      0.87      0.89        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.93      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       221\n",
            "           1       0.81      0.85      0.83        20\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.90      0.92      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       223\n",
            "           1       0.88      0.83      0.86        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.91      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9626556016597511\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       219\n",
            "           1       0.76      0.86      0.81        22\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.87      0.92      0.89       241\n",
            "weighted avg       0.97      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      0.96      0.98        24\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      0.98      0.99       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       221\n",
            "           1       0.94      0.85      0.89        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       223\n",
            "           1       1.00      0.83      0.91        18\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.99      0.92      0.95       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       225\n",
            "           1       0.94      0.94      0.94        16\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.97      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       226\n",
            "           1       0.92      0.73      0.81        15\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.86      0.90       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       221\n",
            "           1       0.94      0.85      0.89        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       216\n",
            "           1       0.88      0.88      0.88        25\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.93      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.86      0.90      0.88        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.95      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       217\n",
            "           1       0.91      0.88      0.89        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.93      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       224\n",
            "           1       0.92      0.71      0.80        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.85      0.89       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       220\n",
            "           1       0.95      0.86      0.90        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.93      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       224\n",
            "           1       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      0.97      0.98       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.89      0.85      0.87        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       216\n",
            "           1       0.91      0.80      0.85        25\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.94      0.90      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       212\n",
            "           1       1.00      0.86      0.93        29\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.93      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       220\n",
            "           1       0.83      0.90      0.86        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.94      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       214\n",
            "           1       1.00      0.74      0.85        27\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.98      0.87      0.92       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       224\n",
            "           1       0.92      0.71      0.80        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.85      0.89       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       220\n",
            "           1       1.00      0.90      0.95        21\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       1.00      0.95      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       222\n",
            "           1       0.94      0.84      0.89        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       223\n",
            "           1       1.00      0.67      0.80        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.83      0.89       241\n",
            "weighted avg       0.98      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       220\n",
            "           1       0.89      0.81      0.85        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.90      0.92       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       219\n",
            "           1       0.95      0.82      0.88        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.91      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       217\n",
            "           1       0.92      0.96      0.94        24\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.96      0.97      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       223\n",
            "           1       0.89      0.89      0.89        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.94      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       222\n",
            "           1       0.89      0.89      0.89        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.94      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       215\n",
            "           1       0.92      0.85      0.88        26\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.92      0.93       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.86      0.90      0.88        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.95      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       216\n",
            "           1       0.95      0.76      0.84        25\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.96      0.88      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       220\n",
            "           1       1.00      0.90      0.95        21\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       1.00      0.95      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       222\n",
            "           1       0.94      0.79      0.86        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.89      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       221\n",
            "           1       0.81      0.85      0.83        20\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.90      0.92      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       221\n",
            "           1       0.89      0.80      0.84        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.90      0.91       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.9626556016597511\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       214\n",
            "           1       0.91      0.74      0.82        27\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.94      0.87      0.90       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       218\n",
            "           1       0.86      0.83      0.84        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.91      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       214\n",
            "           1       0.92      0.89      0.91        27\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.94      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       220\n",
            "           1       1.00      0.86      0.92        21\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.99      0.93      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       220\n",
            "           1       0.82      0.86      0.84        21\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.90      0.92      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       221\n",
            "           1       0.77      0.85      0.81        20\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.88      0.91      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       226\n",
            "           1       0.92      0.73      0.81        15\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.86      0.90       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       215\n",
            "           1       0.89      0.92      0.91        26\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9626556016597511\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       218\n",
            "           1       0.85      0.74      0.79        23\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.91      0.86      0.89       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       223\n",
            "           1       0.95      1.00      0.97        18\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       0.97      1.00      0.99       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       216\n",
            "           1       0.95      0.72      0.82        25\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.96      0.86      0.90       241\n",
            "weighted avg       0.97      0.97      0.96       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       220\n",
            "           1       0.91      0.95      0.93        21\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.95      0.97      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       223\n",
            "           1       0.81      0.94      0.87        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.90      0.96      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       223\n",
            "           1       0.88      0.78      0.82        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.88      0.91       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       219\n",
            "           1       0.91      0.95      0.93        22\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.95      0.97      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       226\n",
            "           1       0.93      0.93      0.93        15\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.96      0.96      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       213\n",
            "           1       0.90      0.93      0.91        28\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.96      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9585062240663901\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       217\n",
            "           1       0.85      0.71      0.77        24\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.91      0.85      0.87       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       217\n",
            "           1       0.88      0.92      0.90        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.95      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       218\n",
            "           1       0.94      0.74      0.83        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.96      0.87      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.9626556016597511\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       211\n",
            "           1       0.96      0.73      0.83        30\n",
            "\n",
            "    accuracy                           0.96       241\n",
            "   macro avg       0.96      0.86      0.90       241\n",
            "weighted avg       0.96      0.96      0.96       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       221\n",
            "           1       0.95      0.90      0.92        20\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.95      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       226\n",
            "           1       0.82      0.93      0.87        15\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.96      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       219\n",
            "           1       0.85      0.77      0.81        22\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.88      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       221\n",
            "           1       0.87      1.00      0.93        20\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.93      0.99      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       224\n",
            "           1       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      0.97      0.98       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       218\n",
            "           1       0.86      0.83      0.84        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.92      0.91      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       225\n",
            "           1       0.82      0.88      0.85        16\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.93      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       218\n",
            "           1       0.84      0.91      0.87        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.95      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98       225\n",
            "           1       0.68      0.94      0.79        16\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.84      0.95      0.89       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       217\n",
            "           1       0.95      0.83      0.89        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.91      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       219\n",
            "           1       1.00      0.77      0.87        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.89      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       220\n",
            "           1       0.91      0.95      0.93        21\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.95      0.97      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       214\n",
            "           1       1.00      0.78      0.88        27\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.89      0.93       241\n",
            "weighted avg       0.98      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       222\n",
            "           1       0.90      0.95      0.92        19\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.95      0.97      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       219\n",
            "           1       0.95      0.86      0.90        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.93      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       221\n",
            "           1       0.95      0.90      0.92        20\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.95      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       222\n",
            "           1       0.81      0.89      0.85        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.90      0.94      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.995850622406639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       221\n",
            "           1       1.00      0.95      0.97        20\n",
            "\n",
            "    accuracy                           1.00       241\n",
            "   macro avg       1.00      0.97      0.99       241\n",
            "weighted avg       1.00      1.00      1.00       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       216\n",
            "           1       1.00      0.80      0.89        25\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.90      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       219\n",
            "           1       0.91      0.95      0.93        22\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.95      0.97      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       225\n",
            "           1       0.80      0.75      0.77        16\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.89      0.87      0.88       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       224\n",
            "           1       0.93      0.76      0.84        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.88      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.991701244813278\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       222\n",
            "           1       0.95      0.95      0.95        19\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.97      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       221\n",
            "           1       0.94      0.80      0.86        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.90      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       223\n",
            "           1       0.84      0.89      0.86        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.94      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       225\n",
            "           1       0.87      0.81      0.84        16\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.90      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       222\n",
            "           1       0.80      0.84      0.82        19\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.89      0.91      0.90       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.83      0.88      0.86        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.93      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       218\n",
            "           1       0.88      0.96      0.92        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.97      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       218\n",
            "           1       0.95      0.78      0.86        23\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.89      0.92       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       217\n",
            "           1       0.83      0.83      0.83        24\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.91      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       222\n",
            "           1       0.89      0.89      0.89        19\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.94      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       219\n",
            "           1       0.90      0.86      0.88        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.93      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       222\n",
            "           1       1.00      0.63      0.77        19\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.98      0.82      0.88       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       216\n",
            "           1       0.95      0.80      0.87        25\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.90      0.93       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       219\n",
            "           1       0.90      0.82      0.86        22\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.90      0.92       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       221\n",
            "           1       0.95      0.90      0.92        20\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.97      0.95      0.96       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       213\n",
            "           1       0.96      0.89      0.93        28\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.94      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.966804979253112\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       218\n",
            "           1       0.80      0.87      0.83        23\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.89      0.92      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       221\n",
            "           1       0.94      0.85      0.89        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       214\n",
            "           1       0.83      0.93      0.88        27\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.91      0.95      0.93       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       220\n",
            "           1       0.87      0.95      0.91        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.93      0.97      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.89      0.85      0.87        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.92      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.9875518672199171\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       215\n",
            "           1       0.93      0.96      0.94        26\n",
            "\n",
            "    accuracy                           0.99       241\n",
            "   macro avg       0.96      0.98      0.97       241\n",
            "weighted avg       0.99      0.99      0.99       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       221\n",
            "           1       0.94      0.85      0.89        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.97      0.92      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       225\n",
            "           1       0.93      0.81      0.87        16\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.90      0.93       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       220\n",
            "           1       0.86      0.86      0.86        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.92      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.85      0.85      0.85        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.92      0.92      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.88      0.88      0.88        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.94      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.88      0.88      0.88        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.94      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       225\n",
            "           1       1.00      0.69      0.81        16\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.84      0.90       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.90      0.90      0.90        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       221\n",
            "           1       0.89      0.80      0.84        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.94      0.90      0.91       241\n",
            "weighted avg       0.97      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       217\n",
            "           1       0.91      0.88      0.89        24\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.93      0.94       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       220\n",
            "           1       1.00      0.71      0.83        21\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.86      0.91       241\n",
            "weighted avg       0.98      0.98      0.97       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       214\n",
            "           1       1.00      0.85      0.92        27\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.99      0.93      0.96       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.975103734439834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       224\n",
            "           1       0.82      0.82      0.82        17\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.91      0.91      0.91       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.983402489626556\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       221\n",
            "           1       0.90      0.90      0.90        20\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.95      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.970954356846473\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       215\n",
            "           1       1.00      0.73      0.84        26\n",
            "\n",
            "    accuracy                           0.97       241\n",
            "   macro avg       0.98      0.87      0.91       241\n",
            "weighted avg       0.97      0.97      0.97       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       214\n",
            "           1       0.92      0.89      0.91        27\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.95      0.94      0.95       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n",
            "Accuracy: 0.979253112033195\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       223\n",
            "           1       0.93      0.78      0.85        18\n",
            "\n",
            "    accuracy                           0.98       241\n",
            "   macro avg       0.96      0.89      0.92       241\n",
            "weighted avg       0.98      0.98      0.98       241\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(pb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWUr-CkFFQCT",
        "outputId": "e0dc4e85-67cb-46ed-fd89-f2950181c0b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0,\n",
              " '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00       223\\n           1       1.00      1.00      1.00        18\\n\\n    accuracy                           1.00       241\\n   macro avg       1.00      1.00      1.00       241\\nweighted avg       1.00      1.00      1.00       241\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = pb.index(max(pb))\n",
        "print(ind)\n",
        "globalbest=chromosomes[ind]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d89etui9FfYk",
        "outputId": "689bad8b-4c79-4fb5-a569-43340580d768"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Selected feature**"
      ],
      "metadata": {
        "id": "--NwaPWyHNxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data(globalbest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROQr84g1Ffwa",
        "outputId": "b52015b0-18a7-48b5-a1a7-9d266bc2f52d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abilities', 'against_bug', 'against_dark', 'against_dragon', 'against_electric', 'against_fire', 'against_flying', 'against_grass', 'against_ground', 'against_normal', 'attack', 'base_egg_steps', 'base_total', 'classfication', 'defense', 'japanese_name', 'name', 'percentage_male', 'pokedex_number', 'sp_defense', 'weight_kg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(globalbest)#new X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5-ZZqM2FtOL",
        "outputId": "905b44e2-4321-4056-c22a-ee0e37351638"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **#this is another way to find the feature selection**"
      ],
      "metadata": {
        "id": "_Siud7MFytPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# negative_values = X[X < 0]\n",
        "# if len(negative_values) > 0:\n",
        "#     raise ValueError(\"Input X contains negative values.\")"
      ],
      "metadata": {
        "id": "gV8d4nLQxwFO",
        "collapsed": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.feature_selection import SelectFromModel\n",
        "# from sklearn.svm import SVC\n",
        "\n",
        "# this_model = RandomForestClassifier(n_estimators=20)\n",
        "# sel= SelectFromModel(estimator= this_model)\n",
        "# sel.fit(X,y)\n",
        "# selected_feature= sel.transform(X)"
      ],
      "metadata": {
        "id": "NObWLbh65eh0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sel.get_support()"
      ],
      "metadata": {
        "id": "Lmhv2tTF7FIo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.svm import SVC\n",
        "\n",
        "# # Assuming X and y are defined and the SelectFromModel process is completed\n",
        "\n",
        "# # Perform train-test split on the selected features\n",
        "# X_train, X_test, y_train, y_test = train_test_split(globalbest, y, test_size=0.3)\n",
        "\n",
        "# # Train SVC model\n",
        "# model_svc = SVC()\n",
        "# model_svc.fit(X_train, y_train)\n",
        "\n",
        "# # Evaluate model\n",
        "# accuracy = model_svc.score(X_test, y_test)\n",
        "# print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "BVm4um2U7Va3",
        "collapsed": true
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **this the hyper parameter**"
      ],
      "metadata": {
        "id": "en8A2nbKn1jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import  GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_hyper= df.drop(labels= 'is_legendary', axis= 1)\n",
        "y_hyper = df['is_legendary']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train_hyper, X_test_hyper, y_train_hyper, y_test_hyper = train_test_split(X_hyper, y_hyper, test_size=0.3, random_state=42)\n",
        "\n",
        "# Choose model\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Set up Grid Search\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search.fit(X_train_hyper, y_train_hyper)\n",
        "\n",
        "# Get best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train model with best hyperparameters\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "best_model.fit(X_train_hyper, y_train_hyper)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = best_model.score(X_test_hyper, y_test_hyper)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQP1AwrwmrMx",
        "outputId": "c97e59ce-37d4-4546-df67-d4672fa3e31f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.995850622406639\n"
          ]
        }
      ]
    }
  ]
}